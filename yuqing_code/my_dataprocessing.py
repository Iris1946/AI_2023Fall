# -*- coding: utf-8 -*-
"""my_dataprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bMepparS3leIOYy1jkdcmr2rEkxq8vGg

# 数据预处理

## 0. 读取数据
"""

from google.colab import drive
drive.mount('/content/drive')

import warnings
import pandas as pd
warnings.filterwarnings('ignore')
import datetime

train_bank = pd.read_csv('drive/MyDrive/AI_Project/data/train_dataset/train_public2.csv')
train_internet = pd.read_csv('drive/MyDrive/AI_Project/data/train_dataset/train_internet2.csv')
test = pd.read_csv('drive/MyDrive/AI_Project/data/test_public2.csv')

train_bank.rename(columns={'isDefault': 'is_default'}, inplace=True)

"""## 1. 合并相同特征

找到train_bank和train_internet表中相同的特征
"""

common_cols = []
for col in train_bank.columns:
    if col in train_internet.columns:
        common_cols.append(col)
    else: continue
len(common_cols)

"""删除train_bank和train_internet不同的特征后合并为“训练集”"""

train_bank_left = list(set(list(train_bank.columns)) - set(common_cols))
train_internet_left = list(set(list(train_internet.columns)) - set(common_cols))

# train_bank删除的特征
train_bank_left

# train_internet删除的特征
train_internet_left

train1_data = train_internet[common_cols]
train2_data = train_bank[common_cols]
train_data = pd.concat([train1_data, train2_data])

test_data = test[common_cols[:-1]]

"""## 2. 处理object类型的特征"""

# 查看训练集的数据类型
train_data.dtypes

# 查看测试集的数据类型
test_data.dtypes

"""发现`class`，`work_year`、`employ_type`、`industry`、`issue_date`、`early_credit_mon`等特征为`object`类型，需要处理为`int`或`float`类型

### class
"""

# 处理前的class特征
train_data['class']

train_data['class'] = train_data['class'].map({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6})
test_data['class'] = test_data['class'].map({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6})

# 处理后的class特征
train_data['class']

"""### work_year"""

# 处理前
train_data['work_year']

work_year_map = {'10+ years': 10, '2 years': 2, '< 1 year': 0, '3 years': 3, '1 year': 1,
     '5 years': 5, '4 years': 4, '6 years': 6, '8 years': 8, '7 years': 7, '9 years': 9}

train_data['work_year']  = train_data['work_year'].map(work_year_map)
test_data['work_year']  = test_data['work_year'].map(work_year_map)

# 处理后
train_data['work_year']

"""### employ_type"""

# 处理前
train_data['employer_type']

employer_type = train1_data['employer_type'].value_counts().index
emp_type_dict = dict(zip(employer_type, [0,1,2,3,4,5]))

train_data['employer_type'] = train_data['employer_type'].map(emp_type_dict)
test_data['employer_type'] = test_data['employer_type'].map(emp_type_dict)

# 处理后
train_data['employer_type']

"""### industry"""

# 处理前
train_data['industry']

industry = train_data['industry'].value_counts().index
industry_dict = dict(zip(industry, [i for i in range(15)]))

train_data['industry'] = train_data['industry'].map(industry_dict)
test_data['industry'] = test_data['industry'].map(industry_dict)

# 处理后
train_data['industry']

"""### issue_date"""

# 处理前
train_data['issue_date']

# 转换为pandas中的日期类型
train_data['issue_date'] = pd.to_datetime(train_data['issue_date'])
# 提取多尺度特征
train_data['issue_date_y'] = train_data['issue_date'].dt.year
train_data['issue_date_m'] = train_data['issue_date'].dt.month
# 提取时间diff
# 设置初始的时间
base_time = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')
# 转换为天为单位
train_data['issue_date_diff'] = train_data['issue_date'].apply(lambda x: x-base_time).dt.days
train_data[['issue_date', 'issue_date_y', 'issue_date_m', 'issue_date_diff']]
train_data.drop('issue_date', axis = 1, inplace = True)

# 转换为pandas中的日期类型
test_data['issue_date'] = pd.to_datetime(test_data['issue_date'])
# 提取多尺度特征
test_data['issue_date_y'] = test_data['issue_date'].dt.year
test_data['issue_date_m'] = test_data['issue_date'].dt.month
# 提取时间diff
# 设置初始的时间
base_time = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')
# 转换为天为单位
test_data['issue_date_diff'] = test_data['issue_date'].apply(lambda x: x-base_time).dt.days
test_data[['issue_date', 'issue_date_y', 'issue_date_m', 'issue_date_diff']]
test_data.drop('issue_date', axis = 1, inplace = True)

# 处理后
train_data[['issue_date_y', 'issue_date_m', 'issue_date_diff']]

"""### early_credit_mon"""

# 处理前
train_data['earlies_credit_mon']

# 转换为pandas中的日期类型
train_data['earlies_credit_mon'] = pd.to_datetime(train_data['earlies_credit_mon'])
# 提取多尺度特征
train_data['earlies_credit_mon_y'] = train_data['earlies_credit_mon'].dt.year
train_data['earlies_credit_mon_m'] = train_data['earlies_credit_mon'].dt.month
# 提取时间diff
# 设置初始的时间
base_time = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')
# 转换为天为单位
train_data['earlies_credit_mon_diff'] = train_data['earlies_credit_mon'].apply(lambda x: x-base_time).dt.days
train_data[['earlies_credit_mon', 'earlies_credit_mon_y', 'earlies_credit_mon_m', 'earlies_credit_mon_diff']]
train_data.drop('earlies_credit_mon', axis = 1, inplace = True)

# 转换为pandas中的日期类型
test_data['earlies_credit_mon'] = pd.to_datetime(test_data['earlies_credit_mon'])
# 提取多尺度特征
test_data['earlies_credit_mon_y'] = test_data['earlies_credit_mon'].dt.year
test_data['earlies_credit_mon_m'] = test_data['earlies_credit_mon'].dt.month
# 提取时间diff
# 设置初始的时间
base_time = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')
# 转换为天为单位
test_data['earlies_credit_mon_diff'] = test_data['earlies_credit_mon'].apply(lambda x: x-base_time).dt.days
test_data[['earlies_credit_mon', 'earlies_credit_mon_y', 'earlies_credit_mon_m', 'earlies_credit_mon_diff']]
test_data.drop('earlies_credit_mon', axis = 1, inplace = True)

# 处理后
train_data[['earlies_credit_mon_y', 'earlies_credit_mon_m', 'earlies_credit_mon_diff']]

"""## 3. 处理缺失值"""

# 检查训练集中的空值情况
train_data.isnull().sum()

# 检查测试集中的空值情况
test_data.isnull().sum()

"""`work_year`, `title`, `pub_dero_bankrup`, `f0`, `f1`, `f2`, `f3`, `f4`列使用`0`填充缺失值"""

train_data[['work_year', 'title', 'pub_dero_bankrup', 'f0', 'f1', 'f2', 'f3', 'f4']] = train_data[['work_year', 'title', 'pub_dero_bankrup', 'f0', 'f1', 'f2', 'f3', 'f4']].fillna(0)
test_data[['work_year', 'pub_dero_bankrup', 'f0', 'f1', 'f2', 'f3', 'f4']] = test_data[['work_year', 'pub_dero_bankrup', 'f0', 'f1', 'f2', 'f3', 'f4']].fillna(0)

"""`debt_loan_ratio`, `recircle_u`使用平均值填充缺失值"""

# 计算多列的平均值
mean_values = train_data[['debt_loan_ratio', 'recircle_u']].mean()

# 用平均值填充多列的缺失值
train_data[['debt_loan_ratio', 'recircle_u']] = train_data[['debt_loan_ratio', 'recircle_u']].fillna(mean_values)

# 检查训练集中是否还存在空值
train_data.isnull().sum()

# 检查测试集中是否还存在空值
test_data.isnull().sum()

"""## 4. 处理异常值"""

import matplotlib.pyplot as plt

# 选择要绘制箱形图的列
columns = train_data.columns

# 设置图形的大小
plt.figure(figsize=(20, 10))

# 循环绘制每一列的箱形图
for i, column in enumerate(columns, 1):
    plt.subplot(7, 6, i)  # 调整子图的布局，根据实际情况调整行和列的数量
    plt.boxplot(train_data[column])
    plt.title(column)

# 调整子图的布局
plt.tight_layout()

# 显示图形
plt.show()

"""## 5. 特征降维

看到特征之间的相关性
"""

import seaborn as sns

# 计算相关性矩阵
correlation_matrix = train_data.corr()

# 设置图形大小
plt.figure(figsize=(15, 12))

# 绘制热力图
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.1f', linewidths=0.5)

# 显示图形
plt.show()

# 查看每个特征和y的相关度，并按绝对值从大到小排序
correlations = train_data.corrwith(train_data['is_default'])
sorted_correlations = correlations.abs().sort_values(ascending=False)
sorted_correlations

"""删选相关度小于0.04的特征"""

# 保留loan_id并设置相关度阈值
correlation_threshold = 0.04

# 根据阈值删除特征
features_to_drop = sorted_correlations[sorted_correlations < correlation_threshold].index

# 如果loan_id在要删除的特征中，将其排除在外
if 'loan_id' in features_to_drop:
    features_to_drop = features_to_drop.drop('loan_id')

# 添加 policy_code 到要删除的特征列表
features_to_drop = features_to_drop.union(['policy_code'])

# 打印将要删除的特征
print("将要删除的特征:")
print(features_to_drop)

# 从数据集中删除特征
train_filtered = train_data.drop(columns=features_to_drop)
test_filtered = test_data.drop(columns=features_to_drop)

# 打印处理后的数据集信息
print("\n处理后的数据集信息:")
train_filtered.info()

train_filtered.to_csv('/content/drive/MyDrive/AI_Project/data/clean_data/train.csv', index=False)
test_filtered.to_csv('/content/drive/MyDrive/AI_Project/data/clean_data/test.csv', index=False)